define({ entries : {
    "Chakraborty2023Possibilities": {
        "abstract": "Our work addresses the critical issue of distinguishing text generated by Large Language Models (LLMs) from human-produced text, a task essential for numerous applications. Despite ongoing debate about the feasibility of such differentiation, we present evidence supporting its consistent achievability, except when human and machine text distributions are indistinguishable across their entire support. Drawing from information theory, we argue that as machine-generated text approximates human-like quality, the sample size needed for detection increases. We establish precise sample complexity bounds for detecting AI-generated text, laying groundwork for future research aimed at developing advanced, multi-sample detectors. Our empirical evaluations across multiple datasets (Xsum, Squad, IMDb, and Kaggle FakeNews) confirm the viability of enhanced detection methods. We test various state-of-the-art text generators, including GPT-2, GPT-3.5-Turbo, Llama, Llama-2-13B-Chat-HF, and Llama-2-70B-Chat-HF, against detectors, including oBERTa-Large/Base-Detector, GPTZero. Our findings align with OpenAI's empirical data related to sequence length, marking the first theoretical substantiation for these observations.",
        "author": "Chakraborty, Souradip and Bedi, Amrit Singh and Zhu, Sicheng and An, Bang and Manocha, Dinesh and Huang, Furong",
        "doi": "10.48550/arXiv.2304.04736",
        "file": "arXiv Fulltext PDF:/Users/wuziyu/Zotero/storage/G4PLBMH9/Chakraborty et al. - 2023 - On the Possibilities of AI-Generated Text Detectio.pdf:application/pdf;arXiv.org Snapshot:/Users/wuziyu/Zotero/storage/BAW79DQC/2304.html:text/html",
        "keywords": "type:evaluation, Artificial Intelligence, Computation and Language, Machine Learning",
        "note": "arXiv:2304.04736 [cs]",
        "publisher": "arXiv",
        "series": "Computation and Language",
        "title": "On the {Possibilities} of {AI}-{Generated} {Text} {Detection}",
        "type": "article",
        "url": "http://arxiv.org/abs/2304.04736",
        "urldate": "2024-05-16",
        "year": "2023"
    },
    "Cingillioglu2023Detecting": {
        "abstract": "Purpose With the advent of ChatGPT, a sophisticated generative artificial intelligence (AI) tool, maintaining academic integrity in all educational settings has recently become a challenge for educators. This paper discusses a method and necessary strategies to confront this challenge. Design/methodology/approach In this study, a language model was defined to achieve high accuracy in distinguishing ChatGPT-generated essays from human written essays with a particular focus on \u201cnot falsely\u201d classifying genuinely human-written essays as AI-generated (Negative). Findings Via support vector machine (SVM) algorithm 100\\% accuracy was recorded for identifying human generated essays. The author discussed the key use of Recall and F2 score for measuring classification performance and the importance of eliminating False Negatives and making sure that no actual human generated essays are incorrectly classified as AI generated. The results of the proposed model's classification algorithms were compared to those of AI-generated text detection software developed by OpenAI, GPTZero and Copyleaks. Practical implications AI-generated essays submitted by students can be detected by teachers and educational designers using the proposed language model and machine learning (ML) classifier at a high accuracy. Human (student)-generated essays can and must be correctly identified with 100\\% accuracy even if the overall classification accuracy performance is slightly reduced. Originality/value This is the first and only study that used an n-gram bag-of-words (BOWs) discrepancy language model as input for a classifier to make such prediction and compared the classification results of other AI-generated text detection software in an empirical way.",
        "author": "Cingillioglu, Ilker",
        "doi": "10.1108/IJILT-03-2023-0043",
        "file": "Snapshot:/Users/wuziyu/Zotero/storage/B33JNLUE/html.html:text/html",
        "issn": "2056-4880",
        "journal": "The International Journal of Information and Learning Technology",
        "keywords": "type:technique, AI generated Text detection, ChatGPT, F2 score, Machine learning, OpenAI, Recall",
        "note": "Publisher: Emerald Publishing Limited",
        "number": "3",
        "pages": "259--268",
        "series": "International Journal of Information and Learning Technology",
        "shorttitle": "Detecting {AI}-generated essays",
        "title": "Detecting {AI}-generated essays: the\u00a0{ChatGPT} challenge",
        "type": "article",
        "url": "https://doi.org/10.1108/IJILT-03-2023-0043",
        "urldate": "2024-05-16",
        "volume": "40",
        "year": "2023"
    },
    "Corizzo2023One-class": {
        "abstract": "Detection of AI-generated content is a crucially important task considering the increasing attention towards AI tools, such as ChatGPT, and the raised concerns with regard to academic integrity. Existing text classification approaches, including neural-network-based and feature-based methods, are mostly tailored for English data, and they are typically limited to a supervised learning setting. Although one-class learning methods are more suitable for classification tasks, their effectiveness in essay detection is still unknown. In this paper, this gap is explored by adopting linguistic features and one-class learning models for AI-generated essay detection. Detection performance of different models is assessed in different settings, where positively labeled data, i.e., AI-generated essays, are unavailable for model training. Results with two datasets containing essays in L2 English and L2 Spanish show that it is feasible to accurately detect AI-generated essays. The analysis reveals which models and which sets of linguistic features are more powerful than others in the detection task.",
        "author": "Corizzo, Roberto and Leal-Arenas, Sebastian",
        "copyright": "http://creativecommons.org/licenses/by/3.0/",
        "doi": "10.3390/app13137901",
        "file": "Full Text PDF:/Users/wuziyu/Zotero/storage/DXTL3MI4/Corizzo and Leal-Arenas - 2023 - One-Class Learning for AI-Generated Essay Detectio.pdf:application/pdf",
        "issn": "2076-3417",
        "journal": "Applied Sciences",
        "keywords": "type:application, ChatGPT, essay classification, L2 writing, linguistics, one-class learning",
        "language": "en",
        "note": "Number: 13",
        "number": "13",
        "pages": "7901",
        "publisher": "Multidisciplinary Digital Publishing Institute",
        "series": "Applied Science",
        "title": "One-{Class} {Learning} for {AI}-{Generated} {Essay} {Detection}",
        "type": "article",
        "url": "https://www.mdpi.com/2076-3417/13/13/7901",
        "urldate": "2024-05-16",
        "volume": "13",
        "year": "2023"
    },
    "Crothers2023Machine": {
        "abstract": "Machine generated text is increasingly difficult to distinguish from human authored text. Powerful open-source models are freely available, and user-friendly tools that democratize access to generative models are proliferating. ChatGPT, which was released shortly after the first edition of this survey, epitomizes these trends. The great potential of state-of-the-art natural language generation (NLG) systems is tempered by the multitude of avenues for abuse. Detection of machine generated text is a key countermeasure for reducing abuse of NLG models, with significant technical challenges and numerous open problems. We provide a survey that includes both 1) an extensive analysis of threat models posed by contemporary NLG systems, and 2) the most complete review of machine generated text detection methods to date. This survey places machine generated text within its cybersecurity and social context, and provides strong guidance for future work addressing the most critical threat models, and ensuring detection systems themselves demonstrate trustworthiness through fairness, robustness, and accountability.",
        "annote": "Comment: Manuscript submitted to ACM Special Session on Trustworthy AI. 2022/11/19 - Updated references",
        "author": "Crothers, Evan and Japkowicz, Nathalie and Viktor, Herna",
        "doi": "10.48550/arXiv.2210.07321",
        "file": "arXiv Fulltext PDF:/Users/wuziyu/Zotero/storage/Q6PGP7EW/Crothers et al. - 2023 - Machine Generated Text A Comprehensive Survey of .pdf:application/pdf;arXiv.org Snapshot:/Users/wuziyu/Zotero/storage/8ZJ3NKWV/2210.html:text/html",
        "keywords": "type:evaluation, Computation and Language, Computers and Society, Cryptography and Security, Machine Learning",
        "note": "arXiv:2210.07321 [cs]",
        "publisher": "arXiv",
        "series": "Computation and Language",
        "shorttitle": "Machine {Generated} {Text}",
        "title": "Machine {Generated} {Text}: {A} {Comprehensive} {Survey} of {Threat} {Models} and {Detection} {Methods}",
        "type": "article",
        "url": "http://arxiv.org/abs/2210.07321",
        "urldate": "2024-05-16",
        "year": "2023"
    },
    "Hu2023Radar": {
        "abstract": "Recent advances in large language models (LLMs) and the intensifying popularity of ChatGPT-like applications have blurred the boundary of high-quality text generation between humans and machines. However, in addition to the anticipated revolutionary changes to our technology and society, the difficulty of distinguishing LLM-generated texts (AI-text) from human-generated texts poses new challenges of misuse and fairness, such as fake content generation, plagiarism, and false accusations of innocent writers. While existing works show that current AI-text detectors are not robust to LLM-based paraphrasing, this paper aims to bridge this gap by proposing a new framework called RADAR, which jointly trains a robust AI-text detector via adversarial learning. RADAR is based on adversarial training of a paraphraser and a detector. The paraphraser's goal is to generate realistic content to evade AI-text detection. RADAR uses the feedback from the detector to update the paraphraser, and vice versa. Evaluated with 8 different LLMs (Pythia, Dolly 2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets, experimental results show that RADAR significantly outperforms existing AI-text detection methods, especially when paraphrasing is in place. We also identify the strong transferability of RADAR from instruction-tuned LLMs to other LLMs, and evaluate the improved capability of RADAR via GPT-3.5-Turbo.",
        "annote": "Comment: Accepted by NeurIPS 2023. Project page and demos: https://radar.vizhub.ai",
        "author": "Hu, Xiaomeng and Chen, Pin-Yu and Ho, Tsung-Yi",
        "doi": "10.48550/arXiv.2307.03838",
        "file": "arXiv Fulltext PDF:/Users/wuziyu/Zotero/storage/NA5D6P9Y/Hu et al. - 2023 - RADAR Robust AI-Text Detection via Adversarial Le.pdf:application/pdf;arXiv.org Snapshot:/Users/wuziyu/Zotero/storage/DC7K6B59/2307.html:text/html",
        "keywords": "type:technique, Artificial Intelligence, Computation and Language, Machine Learning",
        "note": "arXiv:2307.03838 [cs]",
        "publisher": "arXiv",
        "series": "Computation and Language",
        "shorttitle": "{RADAR}",
        "title": "{RADAR}: {Robust} {AI}-{Text} {Detection} via {Adversarial} {Learning}",
        "type": "article",
        "url": "http://arxiv.org/abs/2307.03838",
        "urldate": "2024-05-16",
        "year": "2023"
    },
    "Mitchell2023Detectgpt": {
        "abstract": "The increasing fluency and widespread usage of large language models (LLMs) highlight the desirability of corresponding tools aiding detection of LLM-generated text. In this paper, we identify a property of the structure of an LLM's probability function that is useful for such detection. Specifically, we demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model's log probability function. Leveraging this observation, we then define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call DetectGPT, does not require training a separate classifier, collecting a dataset of real or generated passages, or explicitly watermarking generated text. It uses only log probabilities computed by the model of interest and random perturbations of the passage from another generic pre-trained language model (e.g., T5). We find DetectGPT is more discriminative than existing zero-shot methods for model sample detection, notably improving detection of fake news articles generated by 20B parameter GPT-NeoX from 0.81 AUROC for the strongest zero-shot baseline to 0.95 AUROC for DetectGPT. See https://ericmitchell.ai/detectgpt for code, data, and other project information.",
        "annote": "Comment: ICML 2023",
        "author": "Mitchell, Eric and Lee, Yoonho and Khazatsky, Alexander and Manning, Christopher D. and Finn, Chelsea",
        "doi": "10.48550/arXiv.2301.11305",
        "file": "arXiv Fulltext PDF:/Users/wuziyu/Zotero/storage/CQXKUTTA/Mitchell et al. - 2023 - DetectGPT Zero-Shot Machine-Generated Text Detect.pdf:application/pdf;arXiv.org Snapshot:/Users/wuziyu/Zotero/storage/Q9G8EJR5/2301.html:text/html",
        "keywords": "type:application, Artificial Intelligence, Computation and Language",
        "note": "arXiv:2301.11305 [cs]",
        "publisher": "arXiv",
        "series": "Computation and Language",
        "shorttitle": "{DetectGPT}",
        "title": "{DetectGPT}: {Zero}-{Shot} {Machine}-{Generated} {Text} {Detection} using {Probability} {Curvature}",
        "type": "article",
        "url": "http://arxiv.org/abs/2301.11305",
        "urldate": "2024-05-16",
        "year": "2023"
    },
    "Perkins2024Detection": {
        "abstract": "This study explores the capability of academic staff assisted by the Turnitin Artificial Intelligence (AI) detection tool to identify the use of AI-generated content in university assessments. 22 different experimental submissions were produced using Open AI\u2019s ChatGPT tool, with prompting techniques used to reduce the likelihood of AI detectors identifying AI-generated content. These submissions were marked by 15 academic staff members alongside genuine student submissions. Although the AI detection tool identified 91\\% of the experimental submissions as containing AI-generated content, only 54.8\\% of the content was identified as AI-generated, underscoring the challenges of detecting AI content when advanced prompting techniques are used. When academic staff members marked the experimental submissions, only 54.5\\% were reported to the academic misconduct process, emphasising the need for greater awareness of how the results of AI detectors may be interpreted. Similar performance in grades was obtained between student submissions and AI-generated content (AI mean grade: 52.3, Student mean grade: 54.4), showing the capabilities of AI tools in producing human-like responses in real-life assessment situations. Recommendations include adjusting the overall strategies for assessing university students in light of the availability of new Generative AI tools. This may include reducing the overall reliance on assessments where AI tools may be used to mimic human writing, or by using AI-inclusive assessments. Comprehensive training must be provided for both academic staff and students so that academic integrity may be preserved.",
        "author": "Perkins, Mike and Roe, Jasper and Postma, Darius and McGaughran, James and Hickerson, Don",
        "doi": "10.1007/s10805-023-09492-6",
        "file": "Submitted Version:/Users/wuziyu/Zotero/storage/YJI3DSB4/Perkins et al. - 2024 - Detection of GPT-4 Generated Text in Higher Educat.pdf:application/pdf",
        "issn": "1572-8544",
        "journal": "Journal of Academic Ethics",
        "keywords": "type:evaluation, AI detection, Artificial intelligence, Assessment design, ChatGPT, GPT-4, Turnitin AI detect",
        "language": "en",
        "number": "1",
        "pages": "89--113",
        "series": "Journal of Academic Ethics",
        "shorttitle": "Detection of {GPT}-4 {Generated} {Text} in {Higher} {Education}",
        "title": "Detection of {GPT}-4 {Generated} {Text} in {Higher} {Education}: {Combining} {Academic} {Judgement} and {Software} to {Identify} {Generative} {AI} {Tool} {Misuse}",
        "type": "article",
        "url": "https://doi.org/10.1007/s10805-023-09492-6",
        "urldate": "2024-05-16",
        "volume": "22",
        "year": "2024"
    },
    "Sadasivan2024Can": {
        "abstract": "The unregulated use of LLMs can potentially lead to malicious consequences such as plagiarism, generating fake news, spamming, etc. Therefore, reliable detection of AI-generated text can be critical to ensure the responsible use of LLMs. Recent works attempt to tackle this problem either using certain model signatures present in the generated text outputs or by applying watermarking techniques that imprint specific patterns onto them. In this paper, we show that these detectors are not reliable in practical scenarios. In particular, we develop a recursive paraphrasing attack to apply on AI text, which can break a whole range of detectors, including the ones using the watermarking schemes as well as neural network-based detectors, zero-shot classifiers, and retrieval-based detectors. Our experiments include passages around 300 tokens in length, showing the sensitivity of the detectors even in the case of relatively long passages. We also observe that our recursive paraphrasing only degrades text quality slightly, measured via human studies, and metrics such as perplexity scores and accuracy on text benchmarks. Additionally, we show that even LLMs protected by watermarking schemes can be vulnerable against spoofing attacks aimed to mislead detectors to classify human-written text as AI-generated, potentially causing reputational damages to the developers. In particular, we show that an adversary can infer hidden AI text signatures of the LLM outputs without having white-box access to the detection method. Finally, we provide a theoretical connection between the AUROC of the best possible detector and the Total Variation distance between human and AI text distributions that can be used to study the fundamental hardness of the reliable detection problem for advanced language models. Our code is publicly available at https://github.com/vinusankars/Reliability-of-AI-text-detectors.",
        "author": "Sadasivan, Vinu Sankar and Kumar, Aounon and Balasubramanian, Sriram and Wang, Wenxiao and Feizi, Soheil",
        "doi": "10.48550/arXiv.2303.11156",
        "file": "arXiv Fulltext PDF:/Users/wuziyu/Zotero/storage/54Q4J5MH/Sadasivan et al. - 2024 - Can AI-Generated Text be Reliably Detected.pdf:application/pdf;arXiv.org Snapshot:/Users/wuziyu/Zotero/storage/TV5QVN9K/2303.html:text/html",
        "keywords": "type:evaluation, Artificial Intelligence, Computation and Language, Machine Learning",
        "note": "arXiv:2303.11156 [cs]",
        "publisher": "arXiv",
        "series": "Computation and Language",
        "title": "Can {AI}-{Generated} {Text} be {Reliably} {Detected}?",
        "type": "article",
        "url": "http://arxiv.org/abs/2303.11156",
        "urldate": "2024-05-16",
        "year": "2024"
    },
    "Tian2024Multiscale": {
        "abstract": "Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may impact the authenticity of texts. Previous works proposed methods to detect these AI-generated texts, including simple ML classifiers, pretrained-model-based zero-shot methods, and finetuned language classification models. However, mainstream detectors always fail on short texts, like SMSes, Tweets, and reviews. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the difficulty of short-text detection without sacrificing long-texts. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase AI text detection as a partial Positive-Unlabeled (PU) problem by regarding these short machine texts as partially ``unlabeled\". Then in this PU context, we propose the length-sensitive Multiscale PU Loss, where a recurrent model in abstraction is used to estimate positive priors of scale-variant corpora. Additionally, we introduce a Text Multiscaling module to enrich training corpora. Experiments show that our MPU method augments detection performance on long AI-generated texts, and significantly improves short-text detection of language model detectors. Language Models trained with MPU could outcompete existing detectors on various short-text and long-text detection benchmarks. The codes are available at https://github.com/mindspore-lab/mindone/tree/master/examples/detect\\_chatgpt and https://github.com/YuchuanTian/AIGC\\_text\\_detector.",
        "annote": "Comment: ICLR2024 (Spotlight)",
        "author": "Tian, Yuchuan and Chen, Hanting and Wang, Xutao and Bai, Zheyuan and Zhang, Qinghua and Li, Ruifeng and Xu, Chao and Wang, Yunhe",
        "doi": "10.48550/arXiv.2305.18149",
        "file": "arXiv Fulltext PDF:/Users/wuziyu/Zotero/storage/UUGUV87Q/Tian et al. - 2024 - Multiscale Positive-Unlabeled Detection of AI-Gene.pdf:application/pdf;arXiv.org Snapshot:/Users/wuziyu/Zotero/storage/R7W9B5IC/2305.html:text/html",
        "keywords": "type:technique, Artificial Intelligence, Computation and Language",
        "note": "arXiv:2305.18149 [cs]",
        "publisher": "arXiv",
        "series": "Computation and Language",
        "title": "Multiscale {Positive}-{Unlabeled} {Detection} of {AI}-{Generated} {Texts}",
        "type": "article",
        "url": "http://arxiv.org/abs/2305.18149",
        "urldate": "2024-05-16",
        "year": "2024"
    },
    "Weber-wulff2023Testing": {
        "abstract": "Recent advances in generative pre-trained transformer large language models have emphasised the potential risks of unfair use of artificial intelligence (AI) generated content in an academic environment and intensified efforts in searching for solutions to detect such content. The paper examines the general functionality of detection tools for artificial intelligence generated text and evaluates them based on accuracy and error type analysis. Specifically, the study seeks to answer research questions about whether existing detection tools can reliably differentiate between human-written text and ChatGPT-generated text, and whether machine translation and content obfuscation techniques affect the detection of AI-generated text. The research covers 12 publicly available tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely used in the academic setting. The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bias towards classifying the output as human-written rather than detecting AI-generated text. Furthermore, content obfuscation techniques significantly worsen the performance of tools. The study makes several significant contributions. First, it summarises up-to-date similar scientific and non-scientific efforts in the field. Second, it presents the result of one of the most comprehensive tests conducted so far, based on a rigorous research methodology, an original document set, and a broad coverage of tools. Third, it discusses the implications and drawbacks of using detection tools for AI-generated text in academic settings.",
        "annote": "Comment: 38 pages, 13 figures and 10 tables, and an appendix with 18 figures. Submitted to the International Journal for Educational Integrity",
        "author": "Weber-Wulff, Debora and Anohina-Naumeca, Alla and Bjelobaba, Sonja and Folt\u00fdnek, Tom\u00e1\u0161 and Guerrero-Dib, Jean and Popoola, Olumide and \u0160igut, Petr and Waddington, Lorna",
        "doi": "10.1007/s40979-023-00146-z",
        "file": "arXiv Fulltext PDF:/Users/wuziyu/Zotero/storage/G4F47LDS/Weber-Wulff et al. - 2023 - Testing of Detection Tools for AI-Generated Text.pdf:application/pdf;arXiv.org Snapshot:/Users/wuziyu/Zotero/storage/WWV22I7X/2306.html:text/html",
        "issn": "1833-2595",
        "journal": "International Journal for Educational Integrity",
        "keywords": "type:evaluation, Artificial Intelligence, Computation and Language, Computers and Society",
        "note": "arXiv:2306.15666 [cs]",
        "number": "1",
        "pages": "26",
        "series": "Computation and Language",
        "title": "Testing of {Detection} {Tools} for {AI}-{Generated} {Text}",
        "type": "article",
        "url": "http://arxiv.org/abs/2306.15666",
        "urldate": "2024-05-16",
        "volume": "19",
        "year": "2023"
    }
}});